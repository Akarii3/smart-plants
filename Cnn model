# import necessary libraries
import tensorflow as tf
from tensorflow.keras.applications import MobileNet
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
import numpy as np

# Step 1: Define Parameters
IMAGESIZE = (224, 224) # Input image size
BATCH_SIZE = 32 # Batch size for training
NUM_EPOCHS = 10 # Number of training epochs
NUM_CLASSES = 30 # Number of plant classes
TRAIN_DATA_DIR = '/PATH/TO/YOUR/DATA' # Path to training data
VALIDATION_DATA_DIR = '/PATH/TO/YOUR/DATA' # Path to validation data

# Step 2: Load and preprocess data using ImageDataGenerator
train_datagen = ImageDataGenerator(rescale=1./255,
                               	rotation_range=20,
                               	width_shift_range=0.2,
                               	height_shift_range=0.2,
                               	shear_range=0.2,
                               	zoom_range=0.2,
                               	horizontal_flip=True,
                               	validation_split=0.2)

train_generator = train_datagen.flow_from_directory(TRAIN_DATA_DIR,
                                                	target_size=IMAGESIZE,
                                                	batch_size=BATCH_SIZE,
                                                	class_mode='categorical',
                                                	subset='training')

validation_generator = train_datagen.flow_from_directory(VALIDATION_DATA_DIR,
                                                    	target_size=IMAGESIZE,
                                                    	batch_size=BATCH_SIZE,
                                                    	class_mode='categorical',
                                                    	subset='validation')
# Step 3: Build the CNN model using transfer learing
# Load pre-trained MobileNet model (excluding the top layers)
base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Add custom layers on top of the base model
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)
predictions = Dense(NUM_CLASSES, activation='softmax')(x)
# Create the final model
model = Model(inputs=base_model.input, outputs=predictions)

# Freeze the base model layers
for layer in base_model.layers:
	layer.trainable = False

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

# Step 4: Train the model
history = model.fit(
	train_generator,
	epochs=NUM_EPOCHS,
	validation_data=validation_generator,
	steps_per_epoch=train_generator.samples // BATCH_SIZE,
	validation_steps=validation_generator.samples // BATCH_SIZE
)

# Step 5: Save the trained model
model.save('plant_classification_cnn.h5')

# Step 6: Convert the model to TensorFlow Lite format
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
with open('plant_classification_cnn.tflite', 'wb') as f:
	f.write(tflite_model)

print("Model saved and converted to TensorFlow Lite format.")
